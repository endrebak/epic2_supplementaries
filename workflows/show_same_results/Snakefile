"""Show that epic2 and SICER gives approximately the same results."""

__author__ = "Endre Bakken Stovner https://github.com/endrebak/"
__license__ = "MIT"

from glob import glob
from os import environ
from subprocess import check_output

import pandas as pd

if not environ.get("TMUX", ""):
    raise Exception("Not using TMUX!")


shell.executable("bash")

prefix = "/mnt/scratch/projects/epic_same_results"

sample_sheet = pd.read_csv("sample_sheet.txt", sep=" ", header=0, index_col=None)
ss = sample_sheet

datasets = set(ss.Dataset)
names = set(ss.Name)
# datasets = ["satrom"]
# datasets

wildcard_constraints:
    chip = "(chip|input)",
    dataset = "({})".format("|".join(datasets)),
    name = "({})".format("|".join(names)),



rule all:
    input:
        expand("{prefix}/data/sicer_results/unique_regions/{significant}_{dataset}_epic2.bed",
               prefix=prefix, dataset=datasets, significant="significant insignificant".split()),
        expand("{prefix}/data/sicer_results/unique_regions/{significant}_{dataset}_sicer.bed",
               prefix=prefix, dataset=datasets, significant="significant insignificant".split()),
        expand("{prefix}/data/sicer_results/same_order/{significant}_{dataset}_sicer.bed",
               prefix=prefix, dataset=datasets, significant="significant insignificant".split()),
        expand("{prefix}/data/sicer_results/same_order/{software}_{dataset}_{significant}.bed",
               prefix=prefix, dataset=datasets, significant="significant".split(), software="epic2 sicer".split())


def getfromss(w):

    return ss[(ss.Type == w.chip) & (ss.Dataset == w.dataset) & (ss.Name == w.name)].File.iloc[0]


rule download:
    output:
        "{prefix}/data/download/{dataset}/{chip}/{name}"
    params:
        f = getfromss
    shell:
        "curl {params.f} > {output[0]}"


def getfiles(w, chip):
    f = list(ss[(ss.Type == chip) & (ss.Dataset == w.dataset)].Name)
    return f



rule run_epic2:
    input:
        chip = lambda w: expand("{prefix}/data/download/{dataset}/{chip}/{name}", prefix=w.prefix, dataset=w.dataset, chip="chip", name=getfiles(w, "chip")),
        input = lambda w: expand("{prefix}/data/download/{dataset}/{chip}/{name}", prefix=w.prefix, dataset=w.dataset, chip="input", name=getfiles(w, "input"))
    output:
        result = "{prefix}/data/epic2_results/{dataset}/fdr_list.csv",
        memory = "{prefix}/data/epic2_results/{dataset}/memory.csv"
    params:
        keep_duplicates = lambda w, input: "" if (len(input.chip) == 1 and len(input.input) == 1) else "-kd"
    resources:
        instances = 1
    threads: 48
    shell:
        "/usr/bin/time -v -o {output.memory} epic2 -oa {params.keep_duplicates} -egf 0.85 -gn hg38 -t {input.chip} -c {input.input} -fdr 1 > {output.result}"



rule concat_files_for_sicer:
    input:
        chip = lambda w: expand("{prefix}/data/download/{dataset}/{chip}/{name}", prefix=w.prefix, dataset=w.dataset, chip="chip", name=getfiles(w, "chip")),
        input = lambda w: expand("{prefix}/data/download/{dataset}/{input}/{name}", prefix=w.prefix, dataset=w.dataset, input="input", name=getfiles(w, "input")),
    output:
        chip = "{prefix}/data/{dataset}_chip.bed",
        input = "{prefix}/data/{dataset}_input.bed"
    resources:
        instances = 1
    run:
        shell("zcat -f {input.chip} > {output.chip}")
        shell("zcat -f {input.input} > {output.input}")


rule run_sicer:
    input:
        chip = "{prefix}/data/{dataset}_chip.bed",
        input = "{prefix}/data/{dataset}_input.bed"
    output:
        result = "{prefix}/data/sicer_results/{dataset}/{dataset}_chip-W200-G600-islands-summary-FDR1.0",
        memory = "{prefix}/data/sicer_results/{dataset}/memory.csv",
    resources:
        instances = 1
    params:
        keep_duplicates = lambda w, input: 1 if (len(input.chip) == 1 and len(input.input == 1)) else int(1e6)
    run:
        pwd = check_output("echo $(dirname $(dirname `pwd`))", shell=True).decode().strip()

        # print("/usr/bin/time -v -o {output.memory} sh ../../SICER/SICER.sh {prefix}/data/ {wildcards.dataset}_chip.bed {wildcards.dataset}_input.bed {prefix}/data/sicer_results/{wildcards.dataset}/{wildcards.bigwig} hg38 1 200 150 0.85 600 1.0 {pwd}".format(**vars()))
        shell("/usr/bin/time -v -o {output.memory} sh ../../SICER/SICER_full.sh {prefix}/data/ {wildcards.dataset}_chip.bed {wildcards.dataset}_input.bed {prefix}/data/sicer_results/{wildcards.dataset}/ hg38 {params.keep_duplicates} 200 150 0.85 600 1.0 {pwd}")


def get_results(w):

    if w.software == "epic2":
        f = "{prefix}/data/epic2_results/{dataset}/fdr_list.csv"
    else:
        f = "{prefix}/data/sicer_results/{dataset}/{dataset}_chip-W200-G600-islands-summary-FDR1.0"

    return f.format(**w)



rule significant_only:
    input:
        get_results
    output:
        "{prefix}/data/sicer_results/{significant}_regions/{dataset}/{software}.bed"
    run:
        df = pd.read_csv(input[0], header=0, sep="\t")

        w = wildcards
        if w.significant == "significant":
            if w.software == "epic2":
                df[df.FDR <= 0.05].to_csv(output[0], sep="\t", index=False)
            else:
                df[df.iloc[:, 7] <= 0.05].to_csv(output[0], sep="\t", index=False)
        else:
            if w.software == "epic2":
                df[df.FDR > 0.05].to_csv(output[0], sep="\t", index=False)
            else:
                df[df.iloc[:, 7] > 0.05].to_csv(output[0], sep="\t", index=False)


rule find_unique_regions_epic2:
    input:
        epic2 = "{prefix}/data/sicer_results/{significant}_regions/{dataset}/epic2.bed",
        sicer =  "{prefix}/data/sicer_results/{significant}_regions/{dataset}/sicer.bed"
    output:
        "{prefix}/data/sicer_results/unique_regions/{significant}_{dataset}_epic2.bed"
    shell:
        "bedtools subtract -a {input.epic2} -b {input.sicer} > {output[0]}"

rule find_unique_regions_sicer:
    input:
        epic2 = "{prefix}/data/sicer_results/{significant}_regions/{dataset}/epic2.bed",
        sicer =  "{prefix}/data/sicer_results/{significant}_regions/{dataset}/sicer.bed"
    output:
        "{prefix}/data/sicer_results/unique_regions/{significant}_{dataset}_sicer.bed"
    shell:
        "bedtools subtract -b {input.epic2} -a {input.sicer} > {output[0]}"

rule sort_and_head:
    input:
        epic2 = "{prefix}/data/sicer_results/{significant}_regions/{dataset}/epic2.bed",
        sicer = "{prefix}/data/sicer_results/{significant}_regions/{dataset}/sicer.bed"
    output:
        sicer = "{prefix}/data/sicer_results/same_order/{significant}_{dataset}_sicer.bed",
        epic2 = "{prefix}/data/sicer_results/same_order/{significant}_{dataset}_epic2.bed"
    run:
        epic2 = pd.read_csv(input.epic2, sep="\t", header=0, usecols=[0, 1, 2, 3])
        epic2 = epic2.rename(columns={"#Chromosome": "Chromosome"})
        sicer = pd.read_csv(input.sicer, sep="\t", header=None, usecols=[0, 1, 2, 5], names="Chromosome Start End PValue".split())

        # first by PValue, then by position, in case they have same score
        sort_by2 = ["PValue", "Chromosome", "Start", "End"]
        epic2 = epic2.sort_values(sort_by2)
        sicer = sicer.sort_values(sort_by2)

        epic2.to_csv(output.epic2, sep="\t", index=False, header=False)
        sicer.to_csv(output.sicer, sep="\t", index=False, header=False)


rule get_intersection_sorted:
    input:
        sicer = "{prefix}/data/sicer_results/same_order/significant_{dataset}_sicer.bed",
        epic2 = "{prefix}/data/sicer_results/same_order/significant_{dataset}_epic2.bed"
    output:
        "{prefix}/data/sicer_results/same_order/sicer_{dataset}_significant.bed"
    shell:
        "bedtools intersect -a <(head -1000 {input[0]}) -b <(head -1000 {input[1]}) > {output[0]}"

rule get_intersection_sorted_epic:
    input:
        sicer = "{prefix}/data/sicer_results/same_order/significant_{dataset}_sicer.bed",
        epic2 = "{prefix}/data/sicer_results/same_order/significant_{dataset}_epic2.bed"
    output:
        "{prefix}/data/sicer_results/same_order/epic2_{dataset}_significant.bed"
    shell:
        "bedtools intersect -a <(head -1000 {input[1]}) -b <(head -1000 {input[0]}) > {output[0]}"
